---
header:
  caption: ""
  image: ""
title: Papers Under Review
---

## Testing the Causal Impact of Social Media Reduction Around the Globe

*Conditionally Accepted at Nature*

[Project Webpage](https://globalsocialmediastudy.com/)

**Abstract:** More than half of the world’s population now uses social media. There is widespread debate among the general public, politicians, and academics about social media’s impact on important variables, such as intergroup conflict and well-being. However, many studies on the impact of social media are either correlational or focus primarily on samples from the United States and Western Europe. We plan to conduct a global field experiment to measure the causal impact of incentivizing people to substantially reduce their social media usage across 23 countries (projected n > 8,000) for two weeks. We will then test hypotheses on how social media reduction influences four main outcomes: news knowledge, exposure to online hostility, intergroup attitudes, and well-being. We will also explore how the effects of social media reduction vary across different world regions, focusing on three theoretically-informed country-level moderators: income level, inequality, and democracy. This large-scale, high-powered global field experiment, and the global dataset resulting from it, will provide much-needed evidence to inform ongoing debates about the impact of social media usage across diverse cultural and political contexts.

*Co-first authors: Steven Rathje, Nejla Asimovic and Tiago Ventura. Coauthors: Sarah Mughal, Claire E. Robertson, Christopher Barrie, ....,  Joshua A. Tucker,  Jay J. Van Bavel. *

## Reducing Social Media Usage During Elections: Evidence from a Multi-Country WhatsApp Deactivation Experiment

*In Preparation. Draft available upon request*

**Abstract:**  Recent research has investigated how social media platforms may spread misinformation and encourage harmful political discourse, which fuels political polarization, prejudice, and offline violence. We deploy online field experiments in Brazil, India, and South Africa to examine how restricting the use of WhatsApp, the world's most widely used messaging app, affects information exposure, political attitudes, and individual well-being. We incentivize participants to either (1) stop consuming multimedia content on WhatsApp or (2) limit overall WhatsApp usage to 10 minutes per day for four weeks ahead of each country's elections. We find that our interventions significantly reduced participants’ exposure to misinformation, online toxicity, and uncivil discussions about politics---but at the expense of keeping up with true political news. Using a wide range of measures, we  detected no changes to political attitudes, but uncovered substantial gains to individual well-being as treated participants substituted WhatsApp usage for other activities. Results highlight the complex trade-offs associated with the effects of social media use on information consumption and its downstream effects. 

*Joint work with Rajeshwari Majumdar, Shelley Liu, Carolina Torreblanca, and Joshua A. Tucker*

## Understanding Beliefs in Misinformation: Repetition, Partisan Signals and Bayesian Processing

*Under Review*

[Paper](https://www.venturatiago.com/talk/ite/ite.pdf)

**Abstract:** Partisan motivations and repeated exposure are two dominant explanations for how individuals form beliefs about political misinformation. 
Yet, there is little research that integrates these processes, despite each pointing to different interventions to combat the spread of false information, especially in online information environments. 
In this paper, we situate both frameworks within a unified Bayesian model of belief formation and design survey experiments to explore several implications of this theoretical framework. 
We find that both partisan motivated reasoning and prior exposure (`illusory truth effects') manifest in our data, and that they exacerbate each other, painting a bleak picture of how the steady drumbeat of partisan-flavored misinformation online influences public beliefs. 
However, we also find that the duration of these biases attenuates sharply over time and that attaching warning labels to false information mitigates the manifestation of both cognitive biases.  
These results contribute to a deeper understanding of cognitive biases in political information processing and provide a structured way of thinking about how best to understand the phenomenon of online misinformation, shifting the focus from the role of mass-level beliefs for falsehoods to the role of political elites and partisan media spreading rumors.

*Joint work with Jim Bisbbe, Sarah Graham and Joshua A. Tucker**

